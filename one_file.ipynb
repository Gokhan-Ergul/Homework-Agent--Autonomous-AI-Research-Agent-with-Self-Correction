{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34790a6-6f89-4939-8e86-cf5aa47152af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END, START\n",
    "from typing import TypedDict, Annotated, Sequence, Any, List, Dict, Optional\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c86f5f8-ace6-40bc-afca-1fda25a5bdc4",
   "metadata": {},
   "source": [
    "# State\n",
    "## 4 Question while detecting if it should be at state or not:\n",
    "**other node needs this information?**\n",
    "\n",
    "\n",
    "**Is This Information \"Global\" Information That Must Be Protected Throughout Its Entire Flow?**\n",
    "\n",
    "\n",
    "**Will This Information Be Used to Decide Where the Stream Will Go?**\n",
    "\n",
    "**Bu Bilgi, Birikmesi (Accumulate) Gereken Bir Bilgi mi?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e54e4ba-5014-4066-8e5b-3937b4d4f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HomeworkState(TypedDict):\n",
    "    does_need_to_rewrite : bool\n",
    "    researcher_result : List[str]\n",
    "    writer_result : str\n",
    "    mistakes : str\n",
    "    messages : Annotated[Sequence[BaseMessage],add_messages]\n",
    "    document_path: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28622f76-6ad7-4927-bc40-d02e0259792a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69144bd3-2c3b-4d0e-a6dc-f377c282a4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761829246.094656     989 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model = 'gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301f195-3c3b-4938-8718-6f22d933a465",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5b86b1-6e6c-4ff5-8e87-e4d01d3ad51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "search_runnable = TavilySearch(max_results = 5)\n",
    "tools = [search_runnable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff6874f3-8665-44c0-aa4b-99df39953a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581a5503-51e4-4e51-b550-66e9b1ef6d46",
   "metadata": {},
   "source": [
    "# Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28036adc-cb6b-4b20-beb4-e701bacf96a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Researcher_agent(state: HomeworkState) -> HomeworkState:\n",
    "    \"\"\"This search agent node recieves the topic and decides to search it on web.\"\"\"\n",
    "\n",
    "    print(\"--- RESEARCHER_agent WORKING ---\")\n",
    "    \n",
    "    message = state['messages']\n",
    "\n",
    "    response = llm_with_tools.invoke(message)\n",
    "    #this will contain AIMessage about tool_call not answer of the llm query.\n",
    "\n",
    "    #after tool run, the response will turn back to reasearcher node by \"Conditional edge (we will set it later.)\"\n",
    "    # messages will be like this:\n",
    "    #HumanMessage (.........)\n",
    "    #AIMessage (..........)\n",
    "    #ToolMessage (...........)\n",
    "    #the second time llm ask itself:Are these search results sufficient? Or do I need more information?\n",
    "    #Senerio A: This results enough.\n",
    "    #Senerio B: These are not enough I want to use the tool again. AIMessage(tool_calls=[...New_query...])\n",
    "    print(\"--- REASEARCHER FINISHED DRAFT ---\")\n",
    "    return {'messages':[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1d82c38-822b-4d22-9a2a-713d1215e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_research_node(state: HomeworkState) -> HomeworkState:\n",
    "    \"\"\"Runs after the search cycle completes.\n",
    "    Finds all ToolMessages in the 'messages' list, collects their contents, and writes them to\n",
    "    the 'researcher_result' key. \"\"\"\n",
    "\n",
    "    print(\"--- compile_research_node WORKING ---\")\n",
    "\n",
    "    \n",
    "    compaile_results = []\n",
    "    messages = state['messages']\n",
    "    for m in messages:\n",
    "        if isinstance(m, ToolMessage):\n",
    "            # The content returned by TavilySearch may already be a list,\n",
    "            # so it might be safer to use 'extend'.\n",
    "            # OR 'append' if you assume the content is a string.\n",
    "            if isinstance(m.content,str):\n",
    "                compaile_results.append(m.content)\n",
    "\n",
    "            elif isinstance(m.content, list):\n",
    "                compaile_results.extend(m.content)\n",
    "    print(\"--- COMPAILE FINISHED DRAFT ---\")\n",
    "\n",
    "    return {'researcher_result': compaile_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0357c61d-46ac-450c-9d52-29ba120c269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.messages import SystemMessage, HumanMessage\n",
    "def writer_agent(state: HomeworkState) -> HomeworkState: #google use docstring like this:\n",
    "    \"\"\"\n",
    "Runs the Writer Agent to synthesize an academic draft in Markdown.\n",
    "\n",
    "This node retrieves sources from the 'researcher_result' key in the state, \n",
    "prompts the LLM to write a formal draft based on those sources, and\n",
    "formats the output as Markdown.\n",
    "\n",
    "Args:\n",
    "    state (Homework_state): The current state of the graph. Must \n",
    "                            contain 'researcher_result'.\n",
    "\n",
    "Returns:\n",
    "    dict: A dictionary with the key 'writer_result' containing the\n",
    "          newly generated Markdown draft.\n",
    "\"\"\"\n",
    "    print(\"--- writer_agent WORKING ---\")\n",
    "    \n",
    "    research_results = state['researcher_result'] # if you give this to llm directly it may not understand so we will give it more readable shape.\n",
    "    sources_text = \"\\n\\n---\\n\\n\".join(research_results)\n",
    "    \n",
    "    does_need_to_rewrite = state.get('does_need_to_rewrite')\n",
    "    \n",
    "    if not does_need_to_rewrite or does_need_to_rewrite == None:        \n",
    "        system_prompt = \"\"\"\n",
    "        You are an expert academic writer. \n",
    "        Your task is to synthesize information from various sources into a coherent, \n",
    "        well-structured academic paper.\n",
    "        You must only use the information provided in the sources.\n",
    "        You must format your entire output in Markdown.\n",
    "        \"\"\"\n",
    "        \n",
    "        user_prompt = f\"\"\"\n",
    "        Here are the research sources:\n",
    "        \n",
    "        <SOURCES>\n",
    "        {sources_text}\n",
    "        </SOURCES>\n",
    "        \n",
    "        Please write an academic draft in Markdown based *only* on these sources.\n",
    "        \"\"\"\n",
    "    \n",
    "        #in here we don't use llm_with_tools because only reaseacher can use it.\n",
    "         # If you use a chat model then you have to use : SystemMessage or HumanMessage. On Reasearch part we will give the input with using HumanMessages.\n",
    "        #SystemMessage: Tells LLM who you are.\n",
    "        #HumanMessage : Tells the request to LLM.\n",
    "\n",
    "    else:\n",
    "        writer_result = state['writer_result']\n",
    "        mistakes = state['mistakes']\n",
    "        \n",
    "        system_prompt = \"\"\"\n",
    "        You are an expert academic editor. \n",
    "        Your task is to rewrite an academic paper to fix specific mistakes.\n",
    "        You must use the <SOURCES> as the single source of truth.\n",
    "        The new paper MUST be in Markdown.\n",
    "        \n",
    "        \"\"\"\n",
    "        user_prompt = f\"\"\"\n",
    "        Here are the original research sources:\n",
    "        \n",
    "        <SOURCES>\n",
    "        {sources_text}\n",
    "        </SOURCES>\n",
    "        \n",
    "        Here is the flawed academic paper:\n",
    "        <PAPER>\n",
    "        {writer_result}\n",
    "        </PAPER>\n",
    "\n",
    "        Here are the mistakes you MUST fix:\n",
    "        <MISTAKES>\n",
    "        {mistakes}\n",
    "        </MISTAKES>\n",
    "        \n",
    "        Please rewrite the entire paper in Markdown, ensuring all mistakes are \n",
    "        corrected and the content strictly follows the sources.\n",
    "        \"\"\"\n",
    "\n",
    "    messages_for_llm = [\n",
    "        SystemMessage(content = system_prompt),\n",
    "        HumanMessage(content = user_prompt)\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages_for_llm)\n",
    "        \n",
    "    markdown_draft = response.content\n",
    "        \n",
    "    print(\"--- WRITER FINISHED DRAFT ---\")\n",
    "        \n",
    "    return {\"writer_result\" : markdown_draft}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89e78dab-ce1a-4909-a8f8-7093641e816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def controller_agent(state: HomeworkState) ->HomeworkState:\n",
    "    \"\"\"This agent controls the rewrite text and source text to detect if there is any hallucination on rewrited text writer_result\n",
    "    \n",
    "    Args:\n",
    "    state (Homework_state): The current state of the graph. Must \n",
    "                            contain 'researcher_result' and 'writer_result '.\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    bool: A boolean with the key 'does_need_to_rewrite' it will say if there is hallucination or not.                    \n",
    "    \"\"\"\n",
    "    print('---CONTROLLER IS RUNNING---')\n",
    "    researcher_result = state['researcher_result']\n",
    "    writer_result = state['writer_result']\n",
    "    \n",
    "    research_results = state['researcher_result'] # if you give this to llm directly it may not understand so we will give it more readable shape.\n",
    "    sources_text = \"\\n\\n---\\n\\n\".join(research_results)\n",
    "    \n",
    "    system_prompt = \"\"\"You are an expert fact-checker and editor. Your task is to compare an academic paper\n",
    "    against its original sources. You must identify *any* statements in the paper that\n",
    "    are NOT supported by the sources (hallucinations) or contradict the sources.\n",
    "\n",
    "    If the paper is perfect and has NO hallucinations, you must respond with \n",
    "    the single word: NONE\n",
    "    \n",
    "    If you find any hallucinations or unsupported claims, you MUST return a \n",
    "    list of the specific mistakes.\"\"\"\n",
    "    \n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "        Here are the research sources:\n",
    "        \n",
    "        <SOURCES>\n",
    "        {sources_text}\n",
    "        </SOURCES>\n",
    "        Here are the rewrited academic paper:\n",
    "        Here is the academic paper to check:\n",
    "        <PAPER>\n",
    "        {writer_result}\n",
    "        </PAPER>\n",
    "        \n",
    "        Remember: Respond with ONLY the word \"NONE\" if there are no errors. Otherwise, list the errors.\n",
    "        \"\"\"\n",
    "    messages_for_llm = [\n",
    "            SystemMessage(content = system_prompt),\n",
    "            HumanMessage(content = user_prompt)\n",
    "        ]\n",
    "    \n",
    "    response = llm.invoke(messages_for_llm)\n",
    "    response_content = response.content.strip()\n",
    "    \n",
    "    if response_content == \"NONE\":\n",
    "        print('---THERE IS NO ERROR.')\n",
    "        print('---CONTROLLER IS FINISHED---')\n",
    "        return {'does_need_to_rewrite':False, 'mistakes': \"\"}\n",
    "        \n",
    "    else:\n",
    "        print('---CONTROLLER FIND SOME ERROR:---')\n",
    "        print('---CONTROLLER IS FINISHED---')\n",
    "        \n",
    "        return {'does_need_to_rewrite':True, 'mistakes': response_content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97b6ac15-f095-4bb2-a3d9-0e730784c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypandoc\n",
    "def formatter(state: HomeworkState) -> HomeworkState:\n",
    "    \"\"\"This is a formatter node. It creates a Word file from text written in Markdown format.\"\"\"\n",
    "    \n",
    "    print('---FORMATTER NODE IS RUNNING ---')\n",
    "\n",
    "    outputfile = 'student_number_homeworkname.docx'\n",
    "    \n",
    "    writer_result = state['writer_result']\n",
    "    \n",
    "    try:\n",
    "        pypandoc.convert_text(\n",
    "            writer_result,\n",
    "            'docx',\n",
    "            format = 'md', #markdown\n",
    "            outputfile= outputfile\n",
    "        )\n",
    "        print(f\"The {outputfile} saved succesfully!.\")\n",
    "        return {\"document_path\": outputfile}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"---THERE IS SOMETHING WRONG THE WORD FILE COUND'T CREATE!---\")\n",
    "        print(e)\n",
    "        return {\"document_path\": None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28d06bc-9c1c-4cbd-ac69-9245e2dd1e08",
   "metadata": {},
   "source": [
    "# Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd1807e5-19a2-4a76-8efe-caf4a92bf360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_contunie(state: HomeworkState) -> str:\n",
    "    \"\"\"The researcher decides the flow after the agent.\"\"\"\n",
    "    last_message = state['messages'][-1]\n",
    "    \n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return 'tool_call'\n",
    "\n",
    "    else:\n",
    "        return 'compile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c8cf736-18ae-49b9-9dc2-963b1d9b179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_rewrite(state: HomeworkState) -> str:\n",
    "    \"\"\"Reads the Auditor's decision and directs the flow.\"\"\"\n",
    "\n",
    "    \n",
    "    if state.get('does_need_to_rewrite') == True:\n",
    "        return 'rewrite'\n",
    "    else:\n",
    "        return 'format'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0801725c-3ae1-4b8e-a9c5-cc2aab64304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(HomeworkState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ead0e0ce-4e7d-4cda-b37e-53090c7dfd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "workflow.add_node('researcher', Researcher_agent)\n",
    "workflow.add_node('compile_research',compile_research_node)\n",
    "workflow.add_node('run_tools', tool_node)\n",
    "workflow.add_node('writer', writer_agent)\n",
    "workflow.add_node('controller',controller_agent)\n",
    "workflow.add_node('formatter',formatter)\n",
    "\n",
    "workflow.add_edge(START,'researcher')\n",
    "workflow.add_conditional_edges(\n",
    "    'researcher',\n",
    "    should_contunie,\n",
    "    {\n",
    "        'tool_call':'run_tools',\n",
    "        'compile':'compile_research'\n",
    "    },\n",
    ")\n",
    "workflow.add_edge('run_tools', 'researcher')\n",
    "workflow.add_edge('compile_research','writer')\n",
    "workflow.add_edge('writer','controller')\n",
    "\n",
    "workflow.add_conditional_edges('controller',\n",
    "                              decide_to_rewrite,\n",
    "                              {\n",
    "                                  \"rewrite\":\"writer\",\n",
    "                                  'format':'formatter'\n",
    "                              })\n",
    "\n",
    "workflow.add_edge('formatter', END)\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fbbdc74-d9ab-47af-a98a-a9ef0e492395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RESEARCHER_agent WORKING ---\n",
      "--- REASEARCHER FINISHED DRAFT ---\n",
      "--- RESEARCHER_agent WORKING ---\n",
      "--- REASEARCHER FINISHED DRAFT ---\n",
      "--- compile_research_node WORKING ---\n",
      "--- COMPAILE FINISHED DRAFT ---\n",
      "--- writer_agent WORKING ---\n",
      "--- WRITER FINISHED DRAFT ---\n",
      "---CONTROLLER IS RUNNING---\n",
      "---CONTROLLER FIND SOME ERROR:---\n",
      "---CONTROLLER IS FINISHED---\n",
      "--- writer_agent WORKING ---\n",
      "--- WRITER FINISHED DRAFT ---\n",
      "---CONTROLLER IS RUNNING---\n",
      "---THERE IS NO ERROR.\n",
      "---CONTROLLER IS FINISHED---\n",
      "---FORMATTER NODE IS RUNNING ---\n",
      "The student_number_homeworkname.docx saved succesfully!.\n"
     ]
    }
   ],
   "source": [
    "user_input = HumanMessage(content='what is the advantages and disadvantages of renewable energy sources?')\n",
    "response = app.invoke({'messages': [user_input]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7663b6e-b8aa-4ca5-9913-b09a987c192a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RESEARCHER_agent WORKING ---\n",
      "--- REASEARCHER FINISHED DRAFT ---\n",
      "--- RESEARCHER_agent WORKING ---\n",
      "--- REASEARCHER FINISHED DRAFT ---\n",
      "--- compile_research_node WORKING ---\n",
      "--- COMPAILE FINISHED DRAFT ---\n",
      "--- writer_agent WORKING ---\n",
      "--- WRITER FINISHED DRAFT ---\n",
      "---CONTROLLER IS RUNNING---\n",
      "---CONTROLLER FIND SOME ERROR:---\n",
      "---CONTROLLER IS FINISHED---\n",
      "--- writer_agent WORKING ---\n",
      "--- WRITER FINISHED DRAFT ---\n",
      "---CONTROLLER IS RUNNING---\n",
      "---THERE IS NO ERROR.\n",
      "---CONTROLLER IS FINISHED---\n",
      "---FORMATTER NODE IS RUNNING ---\n",
      "The student_number_homeworkname.docx saved succesfully!.\n"
     ]
    }
   ],
   "source": [
    "user_input = HumanMessage(content='10 interview questions and answers about machine learning.')\n",
    "response = app.invoke({'messages': [user_input]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d6200b-1457-400e-b1e9-c00d15801dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b683baca-414c-4327-b8f6-988c1c96a334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef6252d-8de2-4aa3-85a6-77f2098b02a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d092143-71c5-45a8-aae0-cd1592ff49e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c2f9e-70eb-42c9-9871-77b3587fba22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9956580-bc9a-4d14-ba7e-c76e9e181206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239d8aa4-921f-45cf-8c3b-3bc24c075471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (GPU)",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
